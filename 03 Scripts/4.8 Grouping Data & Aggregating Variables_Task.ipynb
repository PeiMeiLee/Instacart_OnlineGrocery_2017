{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "384959b9",
   "metadata": {},
   "source": [
    "**1. Create a new notebook for this task. Be sure to import the relevant libraries, along with your ords_prods_merge dataframe, which should include your newly derived columns from the previous Exercise.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc7cd36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f45077",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/peimei/09-2023 Instacart Basket Analysis/02 Data/Prepared Data/orders_prods_merged_updated.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Set path and import data\u001b[39;00m\n\u001b[1;32m      3\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/peimei/09-2023 Instacart Basket Analysis\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m ords_prods_merge \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m02 Data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrepared Data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morders_prods_merged_updated.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      5\u001b[0m ords_prods_merge\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/pickle.py:190\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    191\u001b[0m     filepath_or_buffer,\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    193\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m    194\u001b[0m     is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    195\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    196\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/peimei/09-2023 Instacart Basket Analysis/02 Data/Prepared Data/orders_prods_merged_updated.pkl'"
     ]
    }
   ],
   "source": [
    "# Set path and import data\n",
    "\n",
    "path = r'/Users/peimei/09-2023 Instacart Basket Analysis'\n",
    "ords_prods_merge = pd.read_pickle(os.path.join(path, '02 Data', 'Prepared Data', 'orders_prods_merged_updated.pkl'))\n",
    "ords_prods_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5333ead4",
   "metadata": {},
   "source": [
    "**2. In this Exercise, you learned how to find the aggregated mean of the “order_number” column grouped by “department_id” for a subset of your dataframe. Now, repeat this process for the entire dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1329d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by \"product_name\"\n",
    "\n",
    "ords_prods_merge.groupby('product_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6ac278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the mean values of \"order_number\" across \"department_id\"\n",
    "\n",
    "ords_prods_merge.groupby('department_id').agg({'order_number':['mean']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80b6465",
   "metadata": {},
   "source": [
    "**3. Analyze the result. How do the results for the entire dataframe differ from those of the subset? Include your comments in a markdown cell below the executed code.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4363ca47",
   "metadata": {},
   "source": [
    "All mean values in the complete dataframe are lower than those in the subset, except department_id 17."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0600be",
   "metadata": {},
   "source": [
    "**4. Follow the instructions in the Exercise for creating a loyalty flag for existing customers using the transform() and loc() functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd8b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column \"max_order\"\n",
    "\n",
    "ords_prods_merge['max_order'] = ords_prods_merge.groupby(['user_id'])['order_number'].transform(np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212b321d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check the output\n",
    "\n",
    "ords_prods_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e8c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loc() to assign labels\n",
    "\n",
    "ords_prods_merge.loc[ords_prods_merge['max_order'] > 40, 'loyalty_flag'] = 'Loyal customer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1333eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ords_prods_merge.loc[(ords_prods_merge['max_order'] <= 40) & (ords_prods_merge['max_order'] > 10), 'loyalty_flag'] = 'Regular customer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e71a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ords_prods_merge.loc[ords_prods_merge['max_order'] <= 10, 'loyalty_flag'] = 'New customer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd19ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a frequency table for column \"loyalty_flag\"\n",
    "\n",
    "ords_prods_merge['loyalty_flag'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d939c70",
   "metadata": {},
   "source": [
    "**5. The marketing team at Instacart wants to know whether there’s a difference between the spending habits of the three types of customers you identified. Use the loyalty flag you created and check the basic statistics of the product prices for each loyalty category (Loyal Customer, Regular Customer, and New Customer). What you’re trying to determine is whether the prices of products purchased by loyal customers differ from those purchased by regular or new customers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5bd4f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform multiple aggregations\n",
    "\n",
    "ords_prods_merge.groupby('loyalty_flag').agg({'prices':['max','mean','min']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc44684",
   "metadata": {},
   "source": [
    "**Observation: Max value (99999) is unexpectedly high! Further investigation on this is necessarry.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b04a420",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Look at the distirbution of prices\n",
    "\n",
    "ords_prods_merge['prices'].drop_duplicates().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db06722a",
   "metadata": {},
   "source": [
    "**Observations:** The normal price range: 1 - 25. The values \"99999\" and \"14900\" are obviously outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0bb1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency table for prices\n",
    "\n",
    "ords_prods_merge['prices'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dbd21e",
   "metadata": {},
   "source": [
    "**Observations:** \n",
    "<br>4429 rows of data have the abnormal price of \"14900\".\n",
    "<br>798 rows of data have the abnormal price of \"99999\".\n",
    "<br>As the total count of rows with abnormal prices is neglectable, removing them is an option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d62ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of rows with abnormal prices\n",
    "\n",
    "df_abnormal_prices = ords_prods_merge.loc[ords_prods_merge['prices'].isin([99999,14900])]\n",
    "df_abnormal_prices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be7348",
   "metadata": {},
   "source": [
    "**Observations:** There are 5127 rows with an abnormal price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd59994",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_abnormal_prices['product_id'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c8c576",
   "metadata": {},
   "source": [
    "**Observations:** Two products with an abnormal price are identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a02e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the product_id 21553 has only one price value\n",
    "\n",
    "df_product_id_21553 = ords_prods_merge.loc[ords_prods_merge['product_id'].isin([21553])]\n",
    "df_product_id_21553['prices'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c103bb6",
   "metadata": {},
   "source": [
    "**Observations:** The product_id 21553 only has one price value, i.e. the abnormal value of 14900. Thus, imputing the value would take much time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a403cff2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check if the product_id 33664 only has one price value\n",
    "\n",
    "df_product_id_33664 = ords_prods_merge.loc[ords_prods_merge['product_id'].isin([33664])]\n",
    "df_product_id_33664['prices'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce229e0",
   "metadata": {},
   "source": [
    "**Observations:** The product_id 33664 only has one price value, i.e. the abnormal value of 99999. Thus, imputing the value would take much time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9352ada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with abnormal prices and update the dataframe\n",
    "# Confirm the output\n",
    "\n",
    "abnormal_prices = [99999,14900]\n",
    "ords_prods_merge.drop(ords_prods_merge[ords_prods_merge['prices'].isin(abnormal_prices)].index, inplace = True)\n",
    "ords_prods_merge['prices'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce07487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform multiple aggregations again\n",
    "\n",
    "ords_prods_merge.groupby('loyalty_flag').agg({'prices':['max','mean','min']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb882cd",
   "metadata": {},
   "source": [
    "**My observations:** \n",
    "<br> 1. All three types of customers have the same max value and the same min value in the prices of products they purchased. \n",
    "<br> 2. The three types of customers spent almost the same amount of money on average, with less than 0.03 (dollars) between the highest spending group (new customers) and the lowest spending group (loyal customers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad152dd",
   "metadata": {},
   "source": [
    "**6. The team now wants to target different types of spenders in their marketing campaigns. This can be achieved by looking at the prices of the items people are buying. Create a spending flag for each user based on the average price across all their orders using the following criteria:\n",
    "If the mean of the prices of products purchased by a user is lower than 10, then flag them as a “Low spender.”\n",
    "If the mean of the prices of products purchased by a user is higher than or equal to 10, then flag them as a “High spender.”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7c05f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean value\n",
    "\n",
    "ords_prods_merge['price_mean'] = ords_prods_merge.groupby(['user_id'])['prices'].transform(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf86904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the outpot\n",
    "\n",
    "pd.options.display.max_rows = None \n",
    "ords_prods_merge.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea332eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spending flag\n",
    "\n",
    "ords_prods_merge.loc[ords_prods_merge['price_mean'] < 10, 'spending_flag'] = 'Low spender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3ac42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ords_prods_merge.loc[ords_prods_merge['price_mean'] >= 10, 'spending_flag'] = 'High spender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e00a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "ords_prods_merge['spending_flag'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c431ac6",
   "metadata": {},
   "source": [
    "**7. In order to send relevant notifications to users within the app (for instance, asking users if they want to buy the same item again), the Instacart team wants you to determine frequent versus non-frequent customers. Create an order frequency flag that marks the regularity of a user’s ordering behavior according to the median in the “days_since_prior_order” column. The criteria for the flag should be as follows:\n",
    "If the median of “days_since_prior_order” is higher than 20, then the customer should be labeled a “Non-frequent customer.”\n",
    "If the median is higher than 10 and lower than or equal to 20, then the customer should be labeled a “Regular customer.”\n",
    "If the median is lower than or equal to 10, then the customer should be labeled a “Frequent customer.”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a2af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column \"median_days_since_last_order\"\n",
    "# Check the output\n",
    "\n",
    "ords_prods_merge['median_days_since_last_order'] = ords_prods_merge.groupby(['user_id'])['no_of_days_since_last_order'].transform(np.median)\n",
    "ords_prods_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316e59ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create order frequency flag\n",
    "\n",
    "ords_prods_merge.loc[ords_prods_merge['median_days_since_last_order'] > 20, 'order_frequency_flag'] = 'Non-frequent customer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bce6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ords_prods_merge.loc[(ords_prods_merge['median_days_since_last_order'] <= 20) & (ords_prods_merge['median_days_since_last_order'] > 10), 'order_frequency_flag'] = 'Regular customer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfabaf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "ords_prods_merge.loc[ords_prods_merge['median_days_since_last_order'] <= 10, 'order_frequency_flag'] = 'Frequent customer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52312df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequeny table for \"order_frequency_flag\"\n",
    "\n",
    "ords_prods_merge['order_frequency_flag'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989de189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the records with null values\n",
    "\n",
    "ords_prods_merge.loc[ords_prods_merge['order_frequency_flag'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a587a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Investigate user_id 159838\n",
    "\n",
    "ords_prods_merge.loc[ords_prods_merge['user_id']== 159838]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7463bc",
   "metadata": {},
   "source": [
    "**Observations:** \n",
    "<br>1. Looking at the complete history of this customer's orders, we can assume that this customer has only made one order and never returned. This can explain why there is no further values in the column \"no_of_days_since_last_order\" for this customer.\n",
    "<br> 2. As this is a normal incident, we can accept the output for \"order_frequency_flag\" as produced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37848523",
   "metadata": {},
   "source": [
    "**8. Ensure your notebook is clean and structured and that your code is well commented.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e013c4a",
   "metadata": {},
   "source": [
    "Done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eabee59",
   "metadata": {},
   "source": [
    "**9. Export your dataframe as a pickle file and store it correctly in your “Prepared Data” folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb69827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe as pkl file\n",
    "\n",
    "ords_prods_merge.to_pickle(os.path.join(path, '02 Data','Prepared Data', 'orders_products_merged_updated_2.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a87b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
